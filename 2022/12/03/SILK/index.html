<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>SILK Preventing Latency Spikes in Log-Structured Merge Key-Value Stores | Smartog</title><meta name="keywords" content="Key Value store"><meta name="author" content="Smartog,2369398685@qq.com"><meta name="copyright" content="Smartog"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="源码：https:&#x2F;&#x2F;github.com&#x2F;theoanab&#x2F;SILK-USENIXATC2019 由悉尼大学Oana Balmau等人2019年在ATC发表，旨在对LSM KVs的长尾延迟进行优化。论文首先通过在RocksDB上的实验表明长尾延迟问题确实存在以及潜在的原因，然后分析了业界针对长尾延迟的解决方案，最后提出了SILK解决方法并在YCSB以及Nutanix工作负载下进行性能验证。 Ba">
<meta property="og:type" content="article">
<meta property="og:title" content="SILK Preventing Latency Spikes in Log-Structured Merge Key-Value Stores">
<meta property="og:url" content="http://example.com/2022/12/03/SILK/index.html">
<meta property="og:site_name" content="Smartog">
<meta property="og:description" content="源码：https:&#x2F;&#x2F;github.com&#x2F;theoanab&#x2F;SILK-USENIXATC2019 由悉尼大学Oana Balmau等人2019年在ATC发表，旨在对LSM KVs的长尾延迟进行优化。论文首先通过在RocksDB上的实验表明长尾延迟问题确实存在以及潜在的原因，然后分析了业界针对长尾延迟的解决方案，最后提出了SILK解决方法并在YCSB以及Nutanix工作负载下进行性能验证。 Ba">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raw.githubusercontent.com/Smartog/picturebed/master/img-a6fc1290619a7baea605c9c79412d4a2.jpg">
<meta property="article:published_time" content="2022-12-03T07:21:02.000Z">
<meta property="article:modified_time" content="2022-12-03T07:24:08.277Z">
<meta property="article:author" content="Smartog">
<meta property="article:tag" content="Key Value store">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/Smartog/picturebed/master/img-a6fc1290619a7baea605c9c79412d4a2.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2022/12/03/SILK/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="/pluginsSrc/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="/pluginsSrc/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'mediumZoom',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: '/pluginsSrc/flickr-justified-gallery/dist/fjGallery.min.js',
      css: '/pluginsSrc/flickr-justified-gallery/dist/fjGallery.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'SILK Preventing Latency Spikes in Log-Structured Merge Key-Value Stores',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-12-03 15:24:08'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.2.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/touxiang.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">80</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">30</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">12</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Smartog</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">SILK Preventing Latency Spikes in Log-Structured Merge Key-Value Stores</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-12-03T07:21:02.000Z" title="发表于 2022-12-03 15:21:02">2022-12-03</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-12-03T07:24:08.277Z" title="更新于 2022-12-03 15:24:08">2022-12-03</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/paper/">paper</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="SILK Preventing Latency Spikes in Log-Structured Merge Key-Value Stores"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div><article class="post-content" id="article-container"><p>源码：<a target="_blank" rel="noopener" href="https://github.com/theoanab/SILK-USENIXATC2019">https://github.com/theoanab/SILK-USENIXATC2019</a></p>
<p>由悉尼大学Oana Balmau等人2019年在ATC发表，旨在对LSM KVs的长尾延迟进行优化。论文首先通过在RocksDB上的实验表明长尾延迟问题确实存在以及潜在的原因，然后分析了业界针对长尾延迟的解决方案，最后提出了SILK解决方法并在YCSB以及Nutanix工作负载下进行性能验证。</p>
<h3 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h3><p>KV存储支持用户操作和内部操作，其中用户操作Get()、Update()、Scan()用来存储和遍历数据，内部操作包括flushing和compaction。更新操作在内存中进行以获得更好性能，flush操作将内存中的数据持久化到磁盘，compaction操作将LSM-tree的低层数据合并到高层。<strong>论文表示在现有的LSM KVs中当面对繁重多变的客户端写负载时长尾延迟问题仍然存在。</strong></p>
<p>现有工作通过减少内部操作开销来提升客户端吞吐量，但是内部操作仍是必要的，由于对这些内部任务的干扰，在正在进行的内部操作期间到达的客户端操作会增加延迟。实际应用中限制内部操作分配到的IO带宽是常见的手段，但当客户端存在突发写请求，触发突发flush操作，当此时恰有众多compaction操作时flush将和compaction争用有限的IO带宽从而速度降低。这将导致内存中数据结构变满最终阻塞后续的写操作。此外，限制compaction速率也是不够的，考虑到LSM-tree底层结构被填满后将阻塞flush，最终阻塞客户端写操作。论文基于RocksDB构建了SILK，其中最重要的思想是I/O调度器：(1)在客户端操作和内部操作之间动态分配带宽 (2)优先考虑可能阻塞客户端操作的内部操作 (3)允许对不太重要的内部操作进行抢占；</p>
<p>LSM-Tree的基本结构就不再赘述，很多论文都有介绍。其中大多数的LSM KVs支持并行compaction操作（除了L0到L1，因为L0中SStable的key range存在重叠），compaction操作涉及磁盘数据读写涉及大量IO开销。系统维护一个内部 FIFO 工作队列，其中将flush和compaction排入队列。当一个新的内部工作请求入队时，它被放置在内部工作队列的末尾。当 Cm 填满时，flush将进入队列。flush操作或者compaction操作后compaction操作可能进入队列。内部工作线程池为内部工作队列中的请求提供服务。</p>
<h4 id="长尾延迟现有业界解决方案"><a href="#长尾延迟现有业界解决方案" class="headerlink" title="长尾延迟现有业界解决方案"></a>长尾延迟现有业界解决方案</h4><ul>
<li><p><strong>RocksDB：</strong></p>
<p>左图对比了RocksDB开启和关闭compaction操作时尾延迟情况，可以看到开启内部compaction操作长尾延迟比没开时高了四个数量级。右图显示利用RocksDB的rate limiter给内部操作限制不同的IO带宽，我们发现给内部操作分配更高带宽可以推迟较高长尾延迟发生时间，但随着数据量积累还是会有内部操作与上层操作争用带宽的情况发生，从而导致较高的尾延迟。</p>
<p>| <img src="https://raw.githubusercontent.com/Smartog/picturebed/master/SILK/image-20221107211527519.png" alt="image-20221107211527519" style="zoom: 50%;" /> | <img src="https://raw.githubusercontent.com/Smartog/picturebed/master/SILK/image-20221107211700309.png" alt="image-20221107211700309" style="zoom:50%;" /> |<br>| :—————————————————————————————: | :—————————————————————————————: |</p>
</li>
<li><p><strong>TRIAD：</strong></p>
<p>通过三个手段减小内部操作开销。将频繁更新的数据保存在内存中从而降低倾斜负载下内部操作的开销、利用log中已经写入的数据优化flush操作、采用基于开销的方式触发L0到L1的合并操作。这种方式会导致随着时间推移上层compaction增加，最终长尾延迟问题仍然存在。</p>
<p><img src="https://raw.githubusercontent.com/Smartog/picturebed/master/SILK/image-20221107211722749.png" alt="image-20221107211722749" style="zoom:50%;" /></p>
</li>
</ul>
<ul>
<li><p><strong>PebblesDB：</strong></p>
<p>允许除了最高层外所有层存在key重叠，当内部guards数量积累到一定程度使触发对最高层的compaction操作，导致后期compaction操作大量抢占IO资源，整个客户端IO被阻塞直到compaction完成。</p>
<p><img src="https://raw.githubusercontent.com/Smartog/picturebed/master/SILK/image-20221107212754119.png" alt="image-20221107212754119" style="zoom:50%;" /></p>
</li>
</ul>
<h4 id="LSM-KVs性能需求"><a href="#LSM-KVs性能需求" class="headerlink" title="LSM KVs性能需求"></a>LSM KVs性能需求</h4><ul>
<li><strong>低长尾延迟、与用户负载匹配的系统吞吐量、较小的内存占用；</strong></li>
</ul>
<p>LSM KV 中的一个常见问题是当客户端写入的突然爆发与长时间运行的资源密集型压缩任务并行发生时，LSM 内部工作和客户端操作之间存在干扰。尽管内部 LSM 操作直接影响客户端延迟，但是系统在处理内部操作时并没有考虑客户端负载。通过以上实验论文总结了三个lesson：</p>
<ul>
<li>尾延迟主要原因为Cm写满导致写操作阻塞；</li>
<li>简单的限制内部操作带宽不能解决flush操作可用带宽受限问题，因为L0到L1的compaction操作优先级没有被保证；</li>
<li>选择性的进行compaction或者只在最高层进行compaction操作短期内可以避免写延迟，但是长期来看可能在某个时间点触发大量合并操作阻塞掉客户端IO；</li>
</ul>
<h3 id="Solutions"><a href="#Solutions" class="headerlink" title="Solutions"></a>Solutions</h3><ul>
<li><p><strong>Opportunistically allocating I/O bandwidth to internal operations.</strong></p>
<p><img src="https://raw.githubusercontent.com/Smartog/picturebed/master/SILK/image-20221107212816704.png" alt="image-20221107212816704" style="zoom:50%;" /></p>
<p>如图实际应用中，客户端负载是不断变化的。在客户端负载较高时，SILK为高层compaction分配更少的IO带宽并利用低负载阶段来处理内部操作的进行。动态的IO调节限制了内部操作和用户操作之间的干扰，同时也避免了内部工作长期积累导致的过载。</p>
</li>
<li><p><strong>Prioritizing internal operations at the lower levels of the tree</strong></p>
<p>SILK将LSM-tree内部操作分成三类：首先，SILK确保flush足够快，在内存中预留足够多的空间使得update操作得以继续。其次，赋予L0到L1的compaction第二优先级，保证L0不会出现写满，从而保证flush得以进行。</p>
</li>
<li><p><strong>Preempting compactions</strong></p>
<p>SILK 将 L1 以下级别的压缩放在第三位，因为虽然它们保持 LSM 树的结构，但它们的及时执行不会在短期内显着影响客户端操作延迟。</p>
</li>
</ul>
<h3 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h3><h4 id="Opportunistically-allocating-I-O-bandwidth"><a href="#Opportunistically-allocating-I-O-bandwidth" class="headerlink" title="Opportunistically allocating I/O bandwidth"></a>Opportunistically allocating I/O bandwidth</h4><p>SILK动态监测用户操作使用的IO并将剩余可用IO带宽分配给内部操作。用户负载监控和速率限制通过一个单独的SILK线程操作，监控粒度取决于负载的波动频率，SILK使用的粒度是10ms。SILK测量用户端使用的带宽$B$/s，假设LSM KV可用带宽大小为$T B$/s，那么SILK将动态的将内部操作带宽调整为$I=T-C-\varepsilon B$ /s。SILK使用标准速率限制器来调整IO带宽，并为flush操作和L0到L1的compaction操作预留一个最小带宽。<strong>为了避免频繁改动Rate Limiter引入过多开销</strong>，SILK只在当前测量值和新测量值差距较大时改变Rate Limiter，论文设置阈值为10MB/s，如果阈值过低将导致频繁调整rate limiter。参数$\varepsilon$是为了处理客户端负载较小的波动，这些波动不足以使用rate limiter调整内部操作的带宽。</p>
<h4 id="Opportunistically-allocating-I-O-bandwidth-1"><a href="#Opportunistically-allocating-I-O-bandwidth-1" class="headerlink" title="Opportunistically allocating I/O bandwidth"></a>Opportunistically allocating I/O bandwidth</h4><p>LSM KVs 内部工作是通过一个内部线程池处理的，SILK维护了两个内部工作线程池：一个用于高优先级的flush操作，一个用于低优先级的compaction操作。</p>
<ul>
<li><p><strong>Flushing：</strong></p>
<p>flush操作也可以使用内部操作的IO带宽，flush带宽最小值要满足在mutable写满前将immutable写入磁盘。SILK实现了两个内存组件，一个flush线程，设置多个内存组件和flush线程可能有利于维持更长时间的客户端高负载。</p>
</li>
<li><p><strong>L0 to L1 compaction：</strong></p>
<p>如果L0到L1的compaction需要处理而compaction线程池中所有线程都在处理更高level的compaction，一个线程将被抢占分配给L0层的compaction使用，SILK采用随机挑选的方式选择被抢占的线程。L0层合并操作可能受到动态IO带宽限制，SILK可以将L0层合并操作暂时用高优先级线程处理，此时上文提高的最小分配带宽将由flush操作和L0层合并操作共享。</p>
</li>
<li><p><strong>Higher-level compactions：</strong></p>
<p>更高level的合并操作通过低优先级线程调度，SILK以单个合并操作或者整个线程池来暂停或者恢复合并操作。有可能L2层的合并操作由于被L0层合并操作抢占而失效，SILK直接将被抢占合并操作已执行的结果丢弃。以及在考虑多个线程并行compaction时线程的数量应该根据总的可用带宽数量和完成一次合并操作需要的带宽数量决定。目前SILK在低优先级线程池中控制分配给合并操作的总带宽，也可以按照compaction紧迫程度更细粒度的分配带宽。</p>
</li>
</ul>
<h3 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h3><p>在Nutanix和TRIAD中将SILK实现为RocksDB的扩展版本，主要在写密集负载下测试了SILK的尾延迟。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><strong>Hardware</strong></th>
<th style="text-align:left">20-core Intel Xeon, with two 10-core 2.8 GHz processors, 256 GB of RAM, and 960GB SSD Samsung 843T、run with 1GB of RAM using Linux control groups</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>Benchmark</strong></td>
<td style="text-align:left">compare the performance of RocksDBSILK and TRIAD-SILK to RocksDB, TRIAD, and a version of RocksDB that uses the auto-tuned rate limiter</td>
</tr>
<tr>
<td style="text-align:center"><strong>Measurements</strong></td>
<td style="text-align:left">负载生成器将请求放置在KV store的工作线程中，延迟在负载生成器端测量，包含排队时间以及处理时间。每秒测量99th尾延迟和吞吐量</td>
</tr>
<tr>
<td style="text-align:center"><strong>Dataset</strong></td>
<td style="text-align:left">大概500G数据，tuple大小可变，数据集预先填充</td>
</tr>
<tr>
<td style="text-align:center"><strong>KV store configuration</strong></td>
<td style="text-align:left">128MB memory component size and two memory components；LSM KV可用总带宽200MB/s; a thread pool of 4 threads for internal operations; 8线程用于客户端，8线程用户内部操作；没有考虑数据压缩和提交日志；</td>
</tr>
</tbody>
</table>
</div>
<h4 id="Nutanix-workload"><a href="#Nutanix-workload" class="headerlink" title="Nutanix workload"></a>Nutanix workload</h4><p><img src="https://raw.githubusercontent.com/Smartog/picturebed/master/SILK/image-20221107212852941.png" alt="image-20221107212852941" style="zoom:50%;" /></p>
<p>采样了Nutanix24小时工作负载，负载主要以写操作为主。上图展示了在该负载下SILK相较于其他系统的性能优势。左图显示SILK改善了尾延迟，右图黑色虚线为用户负载的吞吐，SILK的工作负载更加接近用户负载而RocksDB存在较大波动。</p>
<p><img src="https://raw.githubusercontent.com/Smartog/picturebed/master/SILK/image-20221107212946371.png" alt="image-20221107212946371" style="zoom: 67%;" /></p>
<p>上图可见SILK中内存组件flush到磁盘的操作不会被阻塞，SILK不会阻塞write操作，当内存组件写满时总能够将其flush到disk中。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="https://raw.githubusercontent.com/Smartog/picturebed/master/SILK/image-20221107213012303.png" alt="image-20221107213012303" style="zoom: 50%;" /></th>
<th style="text-align:center"><img src="https://raw.githubusercontent.com/Smartog/picturebed/master/SILK/image-20221107213023899.png" alt="image-20221107213023899" style="zoom: 67%;" /></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
</div>
<p>上图中SILK在Nutanix24小时工作负载下的长尾延迟和吞吐数据都很平稳，右图分析了IO带宽的分配情况。</p>
<h4 id="YCSB-benchmarks"><a href="#YCSB-benchmarks" class="headerlink" title="YCSB benchmarks"></a>YCSB benchmarks</h4><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="https://raw.githubusercontent.com/Smartog/picturebed/master/SILK/image-20221107213103659.png" alt="image-20221107213103659" style="zoom: 50%;" /></th>
<th style="text-align:center"><img src="https://raw.githubusercontent.com/Smartog/picturebed/master/SILK/image-20221107213126983.png" alt="image-20221107213126983" style="zoom: 50%;" /></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
</div>
<p>在YCSB六个工作负载上测试SILK性能。在uniform和zipfian两种负载分布下SILK对吞吐量影响都很小。右图显示在写密集负载下SILK对长尾延迟的优化更加明显。</p>
<h4 id="Stress-testing-for-long-peaks"><a href="#Stress-testing-for-long-peaks" class="headerlink" title="Stress testing for long peaks"></a>Stress testing for long peaks</h4><p><img src="https://raw.githubusercontent.com/Smartog/picturebed/master/SILK/image-20221107212912873.png" alt="image-20221107212912873" style="zoom:50%;" /></p>
<p>压力测试表明对于较短的负载尖峰和写操作占比，SILK对尾延迟的优化效果较好，当负载尖峰持续时间增加，写操作比例增加，系统无法为内部操作分配足够的资源，系统性能最终下降。并且写操作的占比也会影响尖峰持续的时间。</p>
<h4 id="Breakdown"><a href="#Breakdown" class="headerlink" title="Breakdown"></a>Breakdown</h4><p><img src="https://raw.githubusercontent.com/Smartog/picturebed/master/SILK/image-20221110093035897.png" alt="image-20221110093035897" style="zoom: 50%;" /></p>
<p>上图展示了SILK使用不同策略下99th延迟和吞吐变化。第一行SILK只使用了动态IO分配，第二行SILK只使用了优先级和抢占，第三行SILK综合了以上两种策略。两种策略单独使用都不能较好的解决尾延迟问题且不能长时间维持用户负载。</p>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>其他不说这篇文章的写作思路很清晰，基本思路就是通过动态分配IO带宽和优先级抢占来保证flush和L0合并操作能够及时处理。疑问点总结如下：</p>
<ul>
<li>rate limiter具体工作原理，文中提到了改动rate limiter有开销，所以设置了一个带宽变化的阈值；</li>
<li>SILK在内存中实现了两个组件一个mutable一个immutable一个flush线程，也提到了更多组件和flush线程可能提升性能，为什么没有去做？有新的困难吗？</li>
<li>在compaction优先级抢占中，SILK会随机挑选一个被抢占的compaction线程，有没有更好的方式比如抢占更不“紧迫”的compaction线程；</li>
<li>被抢占的线程已做的工作不会被保存，会被直接丢弃，可以再优化吗？保存一些工作量；</li>
<li>在分配带宽的时候粒度可以更细吗？比如根据compaction任务的紧迫程度分配带宽；</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://example.com">Smartog</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2022/12/03/SILK/">http://example.com/2022/12/03/SILK/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">Smartog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Key-Value-store/">Key Value store</a></div><div class="post_share"><div class="social-share" data-image="https://raw.githubusercontent.com/Smartog/picturebed/master/img-a6fc1290619a7baea605c9c79412d4a2.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="/pluginsSrc/butterfly-extsrc/ShareJS/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="/pluginsSrc/butterfly-extsrc/ShareJS/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://img-blog.csdnimg.cn/9732abb7d2ec4ba09cba5cf29507e04f.jpeg" target="_blank"><img class="post-qr-code-img" src="https://img-blog.csdnimg.cn/9732abb7d2ec4ba09cba5cf29507e04f.jpeg" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://img-blog.csdnimg.cn/899038c3a02c4a14925da419444eb3a4.jpeg" target="_blank"><img class="post-qr-code-img" src="https://img-blog.csdnimg.cn/899038c3a02c4a14925da419444eb3a4.jpeg" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/02/02/%E7%BA%A0%E5%88%A0%E7%A0%81%E8%B0%83%E7%A0%94/"><img class="prev-cover" src="https://raw.githubusercontent.com/Smartog/picturebed/master/img-91c6a55525b25b0bc9ed2b3dee91024f.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">纠删码调研</div></div></a></div><div class="next-post pull-right"><a href="/2022/10/27/Databases/"><img class="next-cover" src="https://raw.githubusercontent.com/Smartog/picturebed/master/img-3b64b597fee35c020340ae93261acc41.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Data Page Layouts for Relational Databases on Deep Memory Hierarchies</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/10/14/ACkey/" title="AC-Key——Adaptive Caching for LSM-based Key-Value Stores"><img class="cover" src="https://raw.githubusercontent.com/Smartog/picturebed/master/img-3b64b597fee35c020340ae93261acc41.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-10-14</div><div class="title">AC-Key——Adaptive Caching for LSM-based Key-Value Stores</div></div></a></div><div><a href="/2022/10/14/Bourbon/" title="From WiscKey to Bourbon A Learned Index for Log-Structured Merge Trees"><img class="cover" src="https://raw.githubusercontent.com/Smartog/picturebed/master/img-a6fc1290619a7baea605c9c79412d4a2.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-10-14</div><div class="title">From WiscKey to Bourbon A Learned Index for Log-Structured Merge Trees</div></div></a></div><div><a href="/2022/10/22/TridentKV/" title="TridentKV A Read-Optimized LSM-Tree Based KV Store via Adaptive Indexing and Space-Effificient Partitioning"><img class="cover" src="https://raw.githubusercontent.com/Smartog/picturebed/master/img-91c6a55525b25b0bc9ed2b3dee91024f.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-10-22</div><div class="title">TridentKV A Read-Optimized LSM-Tree Based KV Store via Adaptive Indexing and Space-Effificient Partitioning</div></div></a></div><div><a href="/2022/08/11/nKV/" title="nKV Near-Data Processing with KV-Stores on Native Computational Storage"><img class="cover" src="https://raw.githubusercontent.com/Smartog/picturebed/master/img-3b64b597fee35c020340ae93261acc41.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-08-11</div><div class="title">nKV Near-Data Processing with KV-Stores on Native Computational Storage</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Background"><span class="toc-number">1.</span> <span class="toc-text">Background</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%95%BF%E5%B0%BE%E5%BB%B6%E8%BF%9F%E7%8E%B0%E6%9C%89%E4%B8%9A%E7%95%8C%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="toc-number">1.1.</span> <span class="toc-text">长尾延迟现有业界解决方案</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#LSM-KVs%E6%80%A7%E8%83%BD%E9%9C%80%E6%B1%82"><span class="toc-number">1.2.</span> <span class="toc-text">LSM KVs性能需求</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Solutions"><span class="toc-number">2.</span> <span class="toc-text">Solutions</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Implementation"><span class="toc-number">3.</span> <span class="toc-text">Implementation</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Opportunistically-allocating-I-O-bandwidth"><span class="toc-number">3.1.</span> <span class="toc-text">Opportunistically allocating I&#x2F;O bandwidth</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Opportunistically-allocating-I-O-bandwidth-1"><span class="toc-number">3.2.</span> <span class="toc-text">Opportunistically allocating I&#x2F;O bandwidth</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Evaluation"><span class="toc-number">4.</span> <span class="toc-text">Evaluation</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Nutanix-workload"><span class="toc-number">4.1.</span> <span class="toc-text">Nutanix workload</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#YCSB-benchmarks"><span class="toc-number">4.2.</span> <span class="toc-text">YCSB benchmarks</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Stress-testing-for-long-peaks"><span class="toc-number">4.3.</span> <span class="toc-text">Stress testing for long peaks</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Breakdown"><span class="toc-number">4.4.</span> <span class="toc-text">Breakdown</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Conclusion"><span class="toc-number">5.</span> <span class="toc-text">Conclusion</span></a></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2024 By Smartog</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Hi, welcome to my <a target="_blank" rel="noopener" href="https://butterfly.js.org/">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="/pluginsSrc/medium-zoom/dist/medium-zoom.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = '/pluginsSrc/mathjax/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script></div><canvas class="fireworks" mobile="false"></canvas><script src="/pluginsSrc/butterfly-extsrc/dist/fireworks.min.js"></script><script defer="defer" id="ribbon" src="/pluginsSrc/butterfly-extsrc/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>